# data for stan
stan_data <- list(
n_subs=n_subs, # N
n_trials=nrow(critical_for_model),
sub_n_new=critical_for_model$sub_n_new,
tdo=critical_for_model$tdo,
display=critical_for_model$display,
probe=critical_for_model$probe,
tdd_5=critical_for_model$tdd_5,
tdd_9=critical_for_model$tdd_9,
tdd_14=critical_for_model$tdd_14,
discrim=critical_for_model$discrim,
n_trials_unique=n_unique,
sub_n_new_unique=critical_unique$sub_n_new,
tdo_unique=critical_unique$tdo,
display_unique=critical_unique$display,
probe_unique=critical_unique$probe,
tdd_5_unique=critical_unique$tdd_5,
tdd_9_unique=critical_unique$tdd_9,
tdd_14_unique=critical_unique$tdd_14
)
# controls
debug_model <- F # whether or not we're testing the model to make sure stan code works
prefix <- "m1" # which model iteration
model_dir <- path(here("analyses","stan",prefix)) # stan files / save directory
stan_model_code <- path(model_dir,glue("{prefix}.stan")) # model code
fit_file <- path(model_dir,glue("{prefix}_fit.RData")) # name of our resulting fit object
if(debug_model){
n_iter <- 100
n_core <- 1
n_chain <- 2
n_warm <- 10
to_save <- F
}else{
# number of iterations for each model per core (for MCMC)
n_iter <- 6000
n_chain <- 4
n_core <- 10
}
if(!file_exists(fit_file) | debug_model){
model_compiled <- stan_model(stan_model_code)
fit <- sampling(model_compiled,
data=stan_data,
chains=n_chain,
cores=n_core,
iter=n_iter)
if(!debug_model) save(fit,file=fit_file)
diagnostics <- get_sampler_params(fit)
if(!debug_model) save(diagnostics, file=path(model_dir,glue("{prefix}_diag.RData")))
}else{
load(fit_file)
fit_summary <- summary(fit,probs=c(.025,.975))
if(!debug_model) save(fit_summary, file=path(model_dir,glue("{prefix}_summary.RData")))
}
# controls
debug_model <- F # whether or not we're testing the model to make sure stan code works
# prefix <- "m2" # which model iteration
for(prefix in c("m2","m3","m4","m5","m6","m7","m8","m9")){
model_dir <- path(here("analyses","stan",prefix)) # stan files / save directory
stan_model_code <- path(model_dir,glue("{prefix}.stan")) # model code
fit_file <- path(model_dir,glue("{prefix}_fit.RData")) # name of our resulting fit object
if(debug_model){
n_iter <- 100
n_core <- 1
n_chain <- 2
n_warm <- 10
to_save <- F
}else{
# number of iterations for each model per core (for MCMC)
n_iter <- 6000
n_chain <- 4
n_core <- 10
}
if(!file_exists(fit_file) | debug_model){
model_compiled <- stan_model(stan_model_code)
fit <- sampling(model_compiled,
data=stan_data,
chains=n_chain,
cores=n_core,
iter=n_iter)
if(!debug_model) save(fit,file=fit_file)
diagnostics <- get_sampler_params(fit)
if(!debug_model) save(diagnostics, file=path(model_dir,glue("{prefix}_diag.RData")))
}else{
load(fit_file)
fit_summary <- summary(fit,probs=c(.025,.975))
if(!debug_model) save(fit_summary, file=path(model_dir,glue("{prefix}_summary.RData")))
}
}
# setup ==============================================================
rm(list=ls())
library(tidyverse)
library(glue)
library(ggsci)
library(tidybayes)
library(fs)
library(rstan)
library(posterior)
library(bayesplot)
library(here)
library(patchwork)
options(digits=5)
read_dat <- function(f){
dd <- read_csv(f) %>%
mutate(display=recode(display, spektor="triangle", trueblood="horizontal"),
across(c(sub_n,tdo,display,choice),as.factor),
display=fct_relevel(display,c("triangle","horizontal")))
return(dd)
}
d <- here("exp1b","data","aggregated","rect_exp1b_aggregated.csv") %>%
read_dat()
# number of ppts
get_subs <- function(d){
p <- length(unique(d$sub_n))
print(p)
return(p)
}
n_subs <- get_subs(d)
# separate data by catch/critical
catch <- d %>%
filter(trial=="catch") %>%
select(-c(tdd,tdo,tw,th,cw,ch,dw,dh,ta,ca,da,probe)) %>%
mutate(correct=case_when(
choice=="l"~1,
choice %in% c("sw","sh")~0
))
critical <- d %>%
filter(trial=="critical")
# checking props on all critical trials ========================================================================================
critical_mean_props_all <- critical %>%
mutate(tdd=as.factor(tdd),
probe=as.factor(probe)) %>%
group_by(sub_n,tdd,probe,choice) %>%
summarise(N=n()) %>%
group_by(sub_n,tdd,probe) %>%
mutate(prop=N/sum(N)) %>%
ungroup() %>%
group_by(tdd,probe,choice) %>%
summarise(m=mean(prop),
s=sd(prop),
N=n(),
se=s/sqrt(N),
ci_lower=m-qt(.975,n()-1)*se,
ci_upper=m+qt(.975,n()-1)*se) %>%
ungroup()
critical_mean_props_all
# critical props on all trial types, all tdd value
critical_mean_props_all %>%
ggplot(aes(tdd,m,col=choice,group=choice))+
geom_point()+
geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),width=.2)+
geom_line()+
scale_y_continuous(limits=c(0,1),breaks=seq(0,1,.2))+
facet_grid(probe~.)+
ggthemes::theme_few()
ggsave(filename=here("analyses","plots","crit_props_all.jpeg"),width=4,height=6)
# critical trial analyses - td and cd ========================================================================================
# NOTE THAT IN THE PAPER WE LABEL COMPETITOR-DECOY TRIALS CD BUT HERE I USE DC
# CHANGED LATER ON IN FIGURE
# baseline display level should be triangle for model
# baseline probe level is cd (dc)
# baseline distance is 2%
critical_1 <- critical %>%
filter(tdd!=0 & probe!="tc") %>% # filter out tc trials
mutate(tdd=as.factor(tdd),
probe=factor(probe,levels=c("dc","td"))) %>%
mutate(display=fct_relevel(display,c("triangle","horizontal")),
discrim=case_when(# whether or not ppt can discriminate from decoy
choice=="t" & probe=="td"~1,
choice=="c" & probe=="dc"~1,
choice=="d"~0
)) %>%
arrange(sub_n,trial_number)
# Compute mean choice proportions, with CIs
# Not using this figure in paper
critical_mean_discrim <- critical_1 %>%
group_by(sub_n,tdd,probe,display) %>%
summarise(p_discrim=mean(discrim)) %>%
group_by(tdd, probe, display) %>%
summarise(mean_discrim=mean(p_discrim),
se=sd(p_discrim)/sqrt(n()),
ci_lower=mean_discrim-qt(.975,n()-1)*se,
ci_upper=mean_discrim+qt(.975,n()-1)*se) %>%
ungroup() %>%
mutate(tdd=as.numeric(as.character(tdd))*100)
critical_mean_discrim %>%
ggplot(aes(tdd, mean_discrim,col=probe))+
geom_point(alpha=.8)+
geom_line(alpha=.8)+
geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),width=.75,alpha=.8)+
facet_grid(.~display)+
scale_x_continuous(breaks=c(2,5,9,14))+
scale_y_continuous(limits=c(.5,1))+
ggsci::scale_color_startrek(name="choice")+
labs(x="target-decoy distance",y="proability discriminate")+
ggthemes::theme_few()+
theme(text=element_text(size=18),
plot.title=element_text(hjust=0.5),
legend.position = "inside",
legend.position.inside = c(.1,.85))
ggsave(filename=here("analyses","plots","critical_discrim_CIs.jpeg"),width=6,height=5)
# Critical TD trials - Statistical modeling ========================================================================
# renumbering subject numbers to go sequentially
# this key specifies which original subject # goes with which new subject #
subs_key <- tibble(
sub_n = sort(unique(critical_1$sub_n)),
sub_n_new = seq(1,n_subs,1)
)
critical_for_model <- tibble(
sub_n=critical_1$sub_n,
trial_number=critical_1$trial_number,
tdo=if_else(critical_1$tdo=="w",1,0),
display=if_else(critical_1$display=="horizontal",1,0),
probe=if_else(critical_1$probe=="td",1,0),
tdd_5=if_else(critical_1$tdd==0.05,1,0),
tdd_9=if_else(critical_1$tdd==0.09,1,0),
tdd_14=if_else(critical_1$tdd==0.14,1,0),
discrim=critical_1$discrim
) %>%
left_join(subs_key) %>% ## assigning "new" subject numbers. Just going sequentially from 1-n subs for easier indexing in stan
relocate(sub_n_new,.after=sub_n)
critical_unique <- critical_for_model %>% # ALL UNIQUE TRIALS FOR PREDICTION IN MODEL
distinct(sub_n_new,tdo,display,probe,tdd_5,tdd_9,tdd_14)
# number of unique trials
n_unique <- nrow(critical_unique)
# data for stan
stan_data <- list(
n_subs=n_subs, # N
n_trials=nrow(critical_for_model),
sub_n_new=critical_for_model$sub_n_new,
tdo=critical_for_model$tdo,
display=critical_for_model$display,
probe=critical_for_model$probe,
tdd_5=critical_for_model$tdd_5,
tdd_9=critical_for_model$tdd_9,
tdd_14=critical_for_model$tdd_14,
discrim=critical_for_model$discrim,
n_trials_unique=n_unique,
sub_n_new_unique=critical_unique$sub_n_new,
tdo_unique=critical_unique$tdo,
display_unique=critical_unique$display,
probe_unique=critical_unique$probe,
tdd_5_unique=critical_unique$tdd_5,
tdd_9_unique=critical_unique$tdd_9,
tdd_14_unique=critical_unique$tdd_14
)
# controls
debug_model <- F # whether or not we're testing the model to make sure stan code works
prefix <- "m9" # which model iteration
model_dir <- path(here("analyses","stan",prefix)) # stan files / save directory
stan_model_code <- path(model_dir,glue("{prefix}.stan")) # model code
fit_file <- path(model_dir,glue("{prefix}_fit.RData")) # name of our resulting fit object
if(debug_model){
n_iter <- 100
n_core <- 1
n_chain <- 2
n_warm <- 10
to_save <- F
}else{
# number of iterations for each model per core (for MCMC)
n_iter <- 6000
n_chain <- 4
n_core <- 10
}
if(!file_exists(fit_file) | debug_model){
model_compiled <- stan_model(stan_model_code)
fit <- sampling(model_compiled,
data=stan_data,
chains=n_chain,
cores=n_core,
iter=n_iter)
if(!debug_model) save(fit,file=fit_file)
diagnostics <- get_sampler_params(fit)
if(!debug_model) save(diagnostics, file=path(model_dir,glue("{prefix}_diag.RData")))
}else{
load(fit_file)
fit_summary <- summary(fit,probs=c(.025,.975))
if(!debug_model) save(fit_summary, file=path(model_dir,glue("{prefix}_summary.RData")))
}
# setup ==============================================================
rm(list=ls())
library(tidyverse)
library(glue)
library(ggsci)
library(tidybayes)
library(fs)
library(rstan)
library(posterior)
library(bayesplot)
library(here)
library(patchwork)
options(digits=5)
read_dat <- function(f){
dd <- read_csv(f) %>%
mutate(display=recode(display, spektor="triangle", trueblood="horizontal"),
across(c(sub_n,tdo,display,choice),as.factor),
display=fct_relevel(display,c("triangle","horizontal")))
return(dd)
}
d <- here("exp1b","data","aggregated","rect_exp1b_aggregated.csv") %>%
read_dat()
# number of ppts
get_subs <- function(d){
p <- length(unique(d$sub_n))
print(p)
return(p)
}
n_subs <- get_subs(d)
# separate data by catch/critical
catch <- d %>%
filter(trial=="catch") %>%
select(-c(tdd,tdo,tw,th,cw,ch,dw,dh,ta,ca,da,probe)) %>%
mutate(correct=case_when(
choice=="l"~1,
choice %in% c("sw","sh")~0
))
critical <- d %>%
filter(trial=="critical")
# checking props on all critical trials ========================================================================================
critical_mean_props_all <- critical %>%
mutate(tdd=as.factor(tdd),
probe=as.factor(probe)) %>%
group_by(sub_n,tdd,probe,choice) %>%
summarise(N=n()) %>%
group_by(sub_n,tdd,probe) %>%
mutate(prop=N/sum(N)) %>%
ungroup() %>%
group_by(tdd,probe,choice) %>%
summarise(m=mean(prop),
s=sd(prop),
N=n(),
se=s/sqrt(N),
ci_lower=m-qt(.975,n()-1)*se,
ci_upper=m+qt(.975,n()-1)*se) %>%
ungroup()
critical_mean_props_all
# critical props on all trial types, all tdd value
critical_mean_props_all %>%
ggplot(aes(tdd,m,col=choice,group=choice))+
geom_point()+
geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),width=.2)+
geom_line()+
scale_y_continuous(limits=c(0,1),breaks=seq(0,1,.2))+
facet_grid(probe~.)+
ggthemes::theme_few()
ggsave(filename=here("analyses","plots","crit_props_all.jpeg"),width=4,height=6)
# critical trial analyses - td and cd ========================================================================================
# NOTE THAT IN THE PAPER WE LABEL COMPETITOR-DECOY TRIALS CD BUT HERE I USE DC
# CHANGED LATER ON IN FIGURE
# baseline display level should be triangle for model
# baseline probe level is cd (dc)
# baseline distance is 2%
critical_1 <- critical %>%
filter(tdd!=0 & probe!="tc") %>% # filter out tc trials
mutate(tdd=as.factor(tdd),
probe=factor(probe,levels=c("dc","td"))) %>%
mutate(display=fct_relevel(display,c("triangle","horizontal")),
discrim=case_when(# whether or not ppt can discriminate from decoy
choice=="t" & probe=="td"~1,
choice=="c" & probe=="dc"~1,
choice=="d"~0
)) %>%
arrange(sub_n,trial_number)
# Compute mean choice proportions, with CIs
# Not using this figure in paper
critical_mean_discrim <- critical_1 %>%
group_by(sub_n,tdd,probe,display) %>%
summarise(p_discrim=mean(discrim)) %>%
group_by(tdd, probe, display) %>%
summarise(mean_discrim=mean(p_discrim),
se=sd(p_discrim)/sqrt(n()),
ci_lower=mean_discrim-qt(.975,n()-1)*se,
ci_upper=mean_discrim+qt(.975,n()-1)*se) %>%
ungroup() %>%
mutate(tdd=as.numeric(as.character(tdd))*100)
critical_mean_discrim %>%
ggplot(aes(tdd, mean_discrim,col=probe))+
geom_point(alpha=.8)+
geom_line(alpha=.8)+
geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),width=.75,alpha=.8)+
facet_grid(.~display)+
scale_x_continuous(breaks=c(2,5,9,14))+
scale_y_continuous(limits=c(.5,1))+
ggsci::scale_color_startrek(name="choice")+
labs(x="target-decoy distance",y="proability discriminate")+
ggthemes::theme_few()+
theme(text=element_text(size=18),
plot.title=element_text(hjust=0.5),
legend.position = "inside",
legend.position.inside = c(.1,.85))
ggsave(filename=here("analyses","plots","critical_discrim_CIs.jpeg"),width=6,height=5)
# Critical TD trials - Statistical modeling ========================================================================
# renumbering subject numbers to go sequentially
# this key specifies which original subject # goes with which new subject #
subs_key <- tibble(
sub_n = sort(unique(critical_1$sub_n)),
sub_n_new = seq(1,n_subs,1)
)
critical_for_model <- tibble(
sub_n=critical_1$sub_n,
trial_number=critical_1$trial_number,
tdo=if_else(critical_1$tdo=="w",1,0),
display=if_else(critical_1$display=="horizontal",1,0),
probe=if_else(critical_1$probe=="td",1,0),
tdd_5=if_else(critical_1$tdd==0.05,1,0),
tdd_9=if_else(critical_1$tdd==0.09,1,0),
tdd_14=if_else(critical_1$tdd==0.14,1,0),
discrim=critical_1$discrim
) %>%
left_join(subs_key) %>% ## assigning "new" subject numbers. Just going sequentially from 1-n subs for easier indexing in stan
relocate(sub_n_new,.after=sub_n)
critical_unique <- critical_for_model %>% # ALL UNIQUE TRIALS FOR PREDICTION IN MODEL
distinct(sub_n_new,tdo,display,probe,tdd_5,tdd_9,tdd_14)
# number of unique trials
n_unique <- nrow(critical_unique)
# data for stan
stan_data <- list(
n_subs=n_subs, # N
n_trials=nrow(critical_for_model),
sub_n_new=critical_for_model$sub_n_new,
tdo=critical_for_model$tdo,
display=critical_for_model$display,
probe=critical_for_model$probe,
tdd_5=critical_for_model$tdd_5,
tdd_9=critical_for_model$tdd_9,
tdd_14=critical_for_model$tdd_14,
discrim=critical_for_model$discrim,
n_trials_unique=n_unique,
sub_n_new_unique=critical_unique$sub_n_new,
tdo_unique=critical_unique$tdo,
display_unique=critical_unique$display,
probe_unique=critical_unique$probe,
tdd_5_unique=critical_unique$tdd_5,
tdd_9_unique=critical_unique$tdd_9,
tdd_14_unique=critical_unique$tdd_14
)
# controls
debug_model <- F # whether or not we're testing the model to make sure stan code works
# controls
debug_model <- F # whether or not we're testing the model to make sure stan code works
for(prefix in c("m9","m10","m11")){
prefix <- "m11" # which model iteration
model_dir <- path(here("analyses","stan",prefix)) # stan files / save directory
stan_model_code <- path(model_dir,glue("{prefix}.stan")) # model code
fit_file <- path(model_dir,glue("{prefix}_fit.RData")) # name of our resulting fit object
if(debug_model){
n_iter <- 100
n_core <- 1
n_chain <- 2
n_warm <- 10
to_save <- F
}else{
# number of iterations for each model per core (for MCMC)
n_iter <- 6000
n_chain <- 4
n_core <- 10
}
if(!file_exists(fit_file) | debug_model){
model_compiled <- stan_model(stan_model_code)
fit <- sampling(model_compiled,
data=stan_data,
chains=n_chain,
cores=n_core,
iter=n_iter)
if(!debug_model) save(fit,file=fit_file)
diagnostics <- get_sampler_params(fit)
if(!debug_model) save(diagnostics, file=path(model_dir,glue("{prefix}_diag.RData")))
}else{
load(fit_file)
fit_summary <- summary(fit,probs=c(.025,.975))
if(!debug_model) save(fit_summary, file=path(model_dir,glue("{prefix}_summary.RData")))
}
}
for(prefix in c("m9","m10","m11")){
# prefix <- "m11" # which model iteration
model_dir <- path(here("analyses","stan",prefix)) # stan files / save directory
stan_model_code <- path(model_dir,glue("{prefix}.stan")) # model code
fit_file <- path(model_dir,glue("{prefix}_fit.RData")) # name of our resulting fit object
if(debug_model){
n_iter <- 100
n_core <- 1
n_chain <- 2
n_warm <- 10
to_save <- F
}else{
# number of iterations for each model per core (for MCMC)
n_iter <- 6000
n_chain <- 4
n_core <- 10
}
if(!file_exists(fit_file) | debug_model){
model_compiled <- stan_model(stan_model_code)
fit <- sampling(model_compiled,
data=stan_data,
chains=n_chain,
cores=n_core,
iter=n_iter)
if(!debug_model) save(fit,file=fit_file)
diagnostics <- get_sampler_params(fit)
if(!debug_model) save(diagnostics, file=path(model_dir,glue("{prefix}_diag.RData")))
}else{
load(fit_file)
fit_summary <- summary(fit,probs=c(.025,.975))
if(!debug_model) save(fit_summary, file=path(model_dir,glue("{prefix}_summary.RData")))
}
}
source("/work/pi_alc_umass_edu/spconway/scratch/rect_2afc/analyses/analysis_for_paper.R", echo=TRUE)
write_csv(pddd, file=path(model_dir,glue("{prefix}_2afc_preds_v_data.csv")))
source("/work/pi_alc_umass_edu/spconway/scratch/rect_2afc/analyses/analysis_for_paper.R", echo=TRUE)
rm(list=ls())
gc()
source("/work/pi_alc_umass_edu/spconway/scratch/rect_2afc/analyses/analysis_for_paper.R", echo=TRUE)
