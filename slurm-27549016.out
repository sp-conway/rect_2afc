Loading r-rocker-ml-verse version 4.4.0+apptainer
Loading apptainer version latest

No apptainer cache directory found. To prevent apptainer from filling up your
home directory, you can create a new directory at
`/work/pi_<your_pi_name>/.apptainer/cache` and reload the module. 

==========
== CUDA ==
==========

CUDA Version 11.8.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.
   Use the NVIDIA Container Toolkit to start this container with GPU support; see
   https://docs.nvidia.com/datacenter/cloud-native/ .

── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
Loading required package: StanHeaders

rstan version 2.32.6 (Stan version 2.32.2)

For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,
change `threads_per_chain` option:
rstan_options(threads_per_chain = 1)


Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

This is posterior version 1.6.0

Attaching package: ‘posterior’

The following objects are masked from ‘package:rstan’:

    ess_bulk, ess_tail

The following objects are masked from ‘package:stats’:

    mad, sd, var

The following objects are masked from ‘package:base’:

    %in%, match

This is bayesplot version 1.11.1
- Online documentation and vignettes at mc-stan.org/bayesplot
- bayesplot theme set to bayesplot::theme_default()
   * Does _not_ affect other ggplot2 plots
   * See ?bayesplot_theme_set for details on theme setting

Attaching package: ‘bayesplot’

The following object is masked from ‘package:posterior’:

    rhat

here() starts at /work/pi_alc_umass_edu/spconway/scratch/rect_2afc
Rows: 35741 Columns: 35
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (9): trial, r1, r2, r3, display, tdo, probe, probe_rects, choice
dbl (26): sub_n, trial_number, w1, h1, w2, h2, w3, h3, tdd, tw, th, cw, ch, ...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
[1] 85
`summarise()` has grouped output by 'sub_n', 'tdd', 'probe'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'tdd', 'probe'. You can override using the
`.groups` argument.
# A tibble: 30 × 9
   tdd   probe choice     m     s     N     se ci_lower ci_upper
   <fct> <fct> <fct>  <dbl> <dbl> <int>  <dbl>    <dbl>    <dbl>
 1 0     dc    c      0.498 0.113    85 0.0123    0.474    0.522
 2 0     dc    d      0.502 0.113    85 0.0123    0.478    0.526
 3 0     tc    c      0.510 0.102    85 0.0110    0.488    0.532
 4 0     tc    t      0.490 0.102    85 0.0110    0.468    0.512
 5 0     td    d      0.505 0.121    85 0.0131    0.479    0.531
 6 0     td    t      0.495 0.121    85 0.0131    0.469    0.521
 7 0.02  dc    c      0.565 0.109    85 0.0118    0.542    0.589
 8 0.02  dc    d      0.435 0.109    85 0.0118    0.411    0.458
 9 0.02  tc    c      0.523 0.103    85 0.0112    0.500    0.545
10 0.02  tc    t      0.477 0.103    85 0.0112    0.455    0.500
# ℹ 20 more rows
`summarise()` has grouped output by 'sub_n', 'tdd', 'probe'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'tdd', 'probe'. You can override using the
`.groups` argument.
Joining with `by = join_by(sub_n)`

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).


SAMPLINGSAMPLING FOR MODEL ' FOR MODEL 'anon_modelanon_model' NOW (CHAIN ' NOW (CHAIN 32).
).

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 1: 
Chain 1: Gradient evaluation took 0.019342 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 193.42 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 2: 
Chain 2: Gradient evaluation took 0.019199 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 191.99 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 3: 
Chain 3: Gradient evaluation took 0.019464 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 194.64 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 4: 
Chain 4: Gradient evaluation took 0.019628 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 196.28 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 2: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 3: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 4: Iteration:    1 / 6000 [  0%]  (Warmup)
Chain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)
Chain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)
Chain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)
Chain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)
Chain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)
Chain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)
Chain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)
Chain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)
Chain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)
Chain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)
Chain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)
Chain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)
Chain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)
Chain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)
Chain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)
Chain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)
Chain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)
Chain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)
Chain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)
Chain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)
Chain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)
Chain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)
Chain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)
Chain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)
Chain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)
Chain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)
Chain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)
Chain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)
Chain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)
Chain 4: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 994.019 seconds (Warm-up)
Chain 4:                1026.96 seconds (Sampling)
Chain 4:                2020.98 seconds (Total)
Chain 4: 
Chain 1: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 1082.1 seconds (Warm-up)
Chain 1:                1043.65 seconds (Sampling)
Chain 1:                2125.75 seconds (Total)
Chain 1: 
Chain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)
Chain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)
Chain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)
Chain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)
Chain 3: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 1080.4 seconds (Warm-up)
Chain 3:                2014.12 seconds (Sampling)
Chain 3:                3094.52 seconds (Total)
Chain 3: 
Chain 2: Iteration: 6000 / 6000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 1155.74 seconds (Warm-up)
Chain 2:                2038.9 seconds (Sampling)
Chain 2:                3194.64 seconds (Total)
Chain 2: 
Warning messages:
1: There were 5 divergent transitions after warmup. See
https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
to find out why this is a problem and how to eliminate them. 
2: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See
https://mc-stan.org/misc/warnings.html#bfmi-low 
3: Examine the pairs() plot to diagnose sampling problems
 
4: The largest R-hat is 1.06, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat 
5: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess 
6: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess 
E-BFMI indicated possible pathological behavior:
  Chain 1: E-BFMI = 0.161
  Chain 2: E-BFMI = 0.070
  Chain 3: E-BFMI = 0.078
  Chain 4: E-BFMI = 0.137
E-BFMI below 0.2 indicates you may need to reparameterize your model.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
Error : object 'm_fit' not found
`summarise()` has grouped output by 'iter', 'display', 'probe'. You can
override using the `.groups` argument.
`summarise()` has grouped output by 'display', 'probe'. You can override using
the `.groups` argument.
`summarise()` has grouped output by 'sub_n', 'display', 'probe'. You can
override using the `.groups` argument.
`summarise()` has grouped output by 'display', 'probe'. You can override using
the `.groups` argument.
[1] -0.014467
Error in check_pars(allpars, pars) : no parameter b_tdd_5_X_td_s
Calls: extract ... extract -> .local -> check_pars_second -> check_pars
Execution halted
